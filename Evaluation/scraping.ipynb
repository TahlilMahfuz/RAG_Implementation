{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q79reDvPwgPn",
        "outputId": "d9feeadf-3ea6-4c8b-9913-e89121e0e0e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google-play-scraper\n",
            "  Downloading google_play_scraper-1.2.7-py3-none-any.whl.metadata (50 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_play_scraper-1.2.7-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: google-play-scraper\n",
            "Successfully installed google-play-scraper-1.2.7\n"
          ]
        }
      ],
      "source": [
        "pip install google-play-scraper\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cgvlPMbT4FwZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google_play_scraper import reviews, Sort\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# App details\n",
        "app_id = \"com.bitsmedia.android.muslimpro\"\n",
        "app_name = \"মুসলিম প্রো: কুরআন আযান নামাজ\"\n",
        "\n",
        "# Configuration\n",
        "batch_size = 10000  # Number of reviews per batch\n",
        "total_reviews = 40000  # Target total to try\n",
        "all_reviews = []\n",
        "continuation_token = None\n",
        "\n",
        "print(\"Starting scraping...\")\n",
        "\n",
        "while len(all_reviews) < total_reviews:\n",
        "    result, continuation_token = reviews(\n",
        "        app_id,\n",
        "        lang='en',  # Adjust if needed\n",
        "        country='us',\n",
        "        sort=Sort.NEWEST,\n",
        "        count=batch_size,\n",
        "        continuation_token=continuation_token\n",
        "    )\n",
        "\n",
        "    # Filter this batch to include only reviews with replies\n",
        "    filtered_batch = [\n",
        "        {\n",
        "            \"content\": r[\"content\"],\n",
        "            \"replyContent\": r[\"replyContent\"],\n",
        "            \"score\": r[\"score\"],\n",
        "            \"app_name\": app_name\n",
        "        }\n",
        "        for r in result if r.get(\"replyContent\")\n",
        "    ]\n",
        "\n",
        "    all_reviews.extend(filtered_batch)\n",
        "    print(f\"Collected {len(all_reviews)} reviews with replies...\")\n",
        "\n",
        "    # Break if no more reviews to fetch\n",
        "    if continuation_token is None:\n",
        "        break\n",
        "\n",
        "    # Be nice to Google servers (sleep optional)\n",
        "    time.sleep(1)\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(all_reviews)\n",
        "\n",
        "# Save to CSV\n",
        "df.to_csv(\"filtered_reviews.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "print(f\"Scraping completed! {len(df)} reviews with replies saved to 'filtered_reviews.csv'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dZqnd1jwvsm",
        "outputId": "d6abdcc4-9c21-48b2-c97c-f80a6bbbdb46"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting scraping...\n",
            "Collected 9523 reviews with replies...\n",
            "Collected 13945 reviews with replies...\n",
            "Collected 18050 reviews with replies...\n",
            "Collected 21027 reviews with replies...\n",
            "Collected 23228 reviews with replies...\n",
            "Collected 26606 reviews with replies...\n",
            "Collected 32621 reviews with replies...\n",
            "Collected 33692 reviews with replies...\n",
            "Collected 34271 reviews with replies...\n",
            "Collected 35402 reviews with replies...\n",
            "Collected 35759 reviews with replies...\n",
            "Collected 36007 reviews with replies...\n",
            "Collected 36885 reviews with replies...\n",
            "Collected 37459 reviews with replies...\n",
            "Collected 37886 reviews with replies...\n",
            "Collected 38623 reviews with replies...\n",
            "Collected 39086 reviews with replies...\n",
            "Collected 39265 reviews with replies...\n",
            "Collected 39460 reviews with replies...\n",
            "Collected 39700 reviews with replies...\n",
            "Collected 40095 reviews with replies...\n",
            "Scraping completed! 40095 reviews with replies saved to 'filtered_reviews.csv'.\n"
          ]
        }
      ]
    }
  ]
}