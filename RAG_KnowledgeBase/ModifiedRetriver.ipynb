{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "671fbc07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from langchain.output_parsers.openai_tools import JsonOutputToolsParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain.chains import create_extraction_chain\n",
    "from typing import Optional, List\n",
    "from langchain.chains import create_extraction_chain_pydantic\n",
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "from langchain import hub\n",
    "from langchain.docstore.document import Document\n",
    "from agentic_chunker import AgenticChunker\n",
    "from cerebras.cloud.sdk import Cerebras\n",
    "from langsmith import Client\n",
    "import json\n",
    "from agentic_chunker import AgenticChunker\n",
    "from langchain.docstore.document import Document\n",
    "from dotenv import load_dotenv\n",
    "from rich import print\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community import embeddings\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "fc51cacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Cerebras client\n",
    "cerebras_api_key = os.getenv(\"CEREBRAS_API_KEY\")\n",
    "if not cerebras_api_key:\n",
    "    raise ValueError(\"CEREBRAS_API_KEY not found in environment variables\")\n",
    "\n",
    "client = Cerebras(api_key=cerebras_api_key)\n",
    "model = \"llama-4-scout-17b-16e-instruct\"\n",
    "\n",
    "# Function to invoke Cerebras API\n",
    "def cerebras_invoke(prompt: str) -> str:\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            model=model,\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] Cerebras API invocation failed: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e76fc924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull the proposal-indexing prompt from the hub\n",
    "LANGSMITH_API_KEY = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "obj = Client(api_key=LANGSMITH_API_KEY).pull_prompt(\"wfh/proposal-indexing\", include_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "35cdd0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentences(BaseModel):\n",
    "    sentences: List[str]\n",
    "\n",
    "def get_propositions(text, prompt):\n",
    "    formatted_prompt = prompt.format(input=text) + \"\\n\\nOnly provide the list of propositions as output. Do not include any explanations, formatting, or additional text.\"\n",
    "    # print(f\"Formatted Prompt: {formatted_prompt}\")\n",
    "    response = cerebras_invoke(formatted_prompt)\n",
    "    # print(f\"Response: {response}\")\n",
    "    propositions = response.split('\\n')\n",
    "    return {\"proposition\": [Sentences(sentences=propositions)]}, response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1f740e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON data\n",
    "with open(\"islamic_etiquette_knowledge_base.json\", \"r\") as f1, open(\"Quran_app_Documentation.json\", \"r\") as f2:\n",
    "    etiquette_data = json.load(f1)\n",
    "    quran_app_data = json.load(f2)\n",
    "\n",
    "# Use only Quran app data as per the query\n",
    "combined_documents = quran_app_data[:2]\n",
    "\n",
    "# List to hold all proposition arrays with metadata\n",
    "proposition_arrays = []\n",
    "\n",
    "# Process each JSON object\n",
    "for json_obj in combined_documents:\n",
    "    text = json_obj['text']\n",
    "    propositions, response = get_propositions(text, obj)\n",
    "    \n",
    "    # Create an array entry for this document's propositions\n",
    "    document_propositions = {\n",
    "        'metadata': {\n",
    "            'url': json_obj['url'],\n",
    "            'title': json_obj['title']\n",
    "        },\n",
    "        'propositions': [\n",
    "            prop for prop in propositions['proposition'][0].sentences if prop.strip()\n",
    "        ]\n",
    "    }\n",
    "    proposition_arrays.append(document_propositions)\n",
    "\n",
    "# If you need a flat list of all propositions with their metadata:\n",
    "flat_propositions_with_metadata = []\n",
    "for doc in proposition_arrays:\n",
    "    for prop in doc['propositions']:\n",
    "        flat_propositions_with_metadata.append({\n",
    "            'proposition': prop,\n",
    "            'metadata': doc['metadata']\n",
    "        })\n",
    "\n",
    "# And if you just need a simple list of all propositions:\n",
    "propositions_list = [prop for doc in proposition_arrays for prop in doc['propositions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "6c8aed14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'url'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'https://gtaf.org/blog/explore-by-topic-in-quran-app/?fbclid=IwY2xjawL0bHxleHRuA2FlbQIxMABicmlkETFmSGVJS3hCRDlCMU5z</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">NUhqAR4oaAxZ-_-1W9pdsQWXvY5qQYbtz6Ti2-byIf6H_WMBG2dXZ-SpAWfi-xsuIQ_aem_CgtPkPGc61w3zh6gIBFt1Q'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Explore the Quran by topics – enhance your knowledge on a topic'</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'url'\u001b[0m: \n",
       "\u001b[32m'https://gtaf.org/blog/explore-by-topic-in-quran-app/?\u001b[0m\u001b[32mfbclid\u001b[0m\u001b[32m=\u001b[0m\u001b[32mIwY2xjawL0bHxleHRuA2FlbQIxMABicmlkETFmSGVJS3hCRDlCMU5z\u001b[0m\n",
       "\u001b[32mNUhqAR4oaAxZ\u001b[0m\u001b[32m-_-1W9pdsQWXvY5qQYbtz6Ti2-byIf6H_WMBG2dXZ-SpAWfi-xsuIQ_aem_CgtPkPGc61w3zh6gIBFt1Q'\u001b[0m,\n",
       "    \u001b[32m'title'\u001b[0m: \u001b[32m'Explore the Quran by topics – enhance your knowledge on a topic'\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(proposition_arrays[0][\"metadata\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daac6274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize AgenticChunker and add propositions\n",
    "ac = AgenticChunker()\n",
    "ac.add_propositions(propositions_list)\n",
    "\n",
    "# Get chunks as a dictionary\n",
    "chunks_dict = ac.get_chunks(get_type='dict')\n",
    "\n",
    "# Create Document objects for each chunk\n",
    "documents = []\n",
    "for chunk in chunks_dict.values():\n",
    "    chunk_propositions = chunk['propositions']\n",
    "    # Collect unique sources for this chunk\n",
    "    unique_sources = set()\n",
    "    for prop in chunk_propositions:\n",
    "        metadata = prop_to_metadata[prop]\n",
    "        unique_sources.add((metadata['url'], metadata['title']))\n",
    "    # Convert unique sources to a list of dictionaries\n",
    "    sources = [{'url': url, 'title': title} for url, title in unique_sources]\n",
    "    # Join propositions into a single string for the document content\n",
    "    chunk_content = \" \".join(chunk_propositions)\n",
    "    # Create metadata with chunk details and sources\n",
    "    metadata = {\n",
    "        'chunk_title': chunk['title'],\n",
    "        'chunk_summary': chunk['summary'],\n",
    "        'sources': sources\n",
    "    }\n",
    "    # Create and append the Document object\n",
    "    doc = Document(page_content=chunk_content, metadata=metadata)\n",
    "    documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82330d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">#### Proposition-Based Chunking ####\n",
       "</pre>\n"
      ],
      "text/plain": [
       "#### Proposition-Based Chunking ####\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Using device: cuda\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Using device: cuda\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Agentic Chunking\n",
    "# print(\"#### Proposition-Based Chunking ####\")\n",
    "\n",
    "# # https://arxiv.org/pdf/2312.06648.pdf\n",
    "# import os\n",
    "# from langchain.output_parsers.openai_tools import JsonOutputToolsParser\n",
    "# from langchain_openai import ChatOpenAI\n",
    "# from langchain_core.prompts import ChatPromptTemplate\n",
    "# from langchain_core.runnables import RunnableLambda\n",
    "# from langchain.chains import create_extraction_chain\n",
    "# from typing import Optional, List\n",
    "# from langchain.chains import create_extraction_chain_pydantic\n",
    "# from pydantic import BaseModel\n",
    "# from langchain import hub\n",
    "# from langsmith import Client\n",
    "# from cerebras.cloud.sdk import Cerebras\n",
    "# from agentic_chunker import AgenticChunker\n",
    "# import os\n",
    "# import json\n",
    "# import uuid\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import faiss\n",
    "# from dotenv import load_dotenv\n",
    "# from typing import Optional\n",
    "# from rich import print\n",
    "# from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "# from rank_bm25 import BM25Okapi\n",
    "# from langchain_community.vectorstores import Chroma\n",
    "# from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "# from langchain.docstore.document import Document\n",
    "# from cerebras.cloud.sdk import Cerebras\n",
    "\n",
    "# # Load environment variables\n",
    "# load_dotenv()\n",
    "\n",
    "# # Initialize device\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1744e8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LANGSMITH_API_KEY = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "# client = Client(api_key=LANGSMITH_API_KEY)\n",
    "# prompt = client.pull_prompt(\"wfh/proposal-indexing\", include_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e7042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  Proposition extraction (simplified from Retriver.ipynb)\n",
    "# def extract_propositions(text: str, chunker: AgenticChunker, prompt: ChatPromptTemplate) -> list:\n",
    "#     formatted_prompt = prompt.format(input=text)\n",
    "#     response = chunker._llm_invoke(formatted_prompt)\n",
    "#     propositions = [line.strip() for line in response.split(\"\\n\") if line.strip()]\n",
    "#     return propositions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a32777e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Agentic chunking with metadata\n",
    "# def perform_agentic_chunking_with_metadata(documents_json: list, prompt: ChatPromptTemplate) -> list:\n",
    "#     ac = AgenticChunker()\n",
    "#     chunked_docs = []\n",
    "\n",
    "#     for doc in documents_json:\n",
    "#         text = doc.get(\"text\", \"\")\n",
    "#         title = doc.get(\"title\", \"Unknown Title\")\n",
    "#         url = doc.get(\"url\", \"Unknown URL\")\n",
    "\n",
    "#         try:\n",
    "#             propositions = extract_propositions(text, ac, prompt)\n",
    "#             ac.add_propositions(propositions)\n",
    "\n",
    "#             agentic_chunks = ac.get_chunks(get_type=\"list_of_strings\")\n",
    "#             for chunk_text in agentic_chunks:\n",
    "#                 chunked_docs.append(Document(\n",
    "#                     page_content=chunk_text,\n",
    "#                     metadata={\n",
    "#                         \"title\": title,\n",
    "#                         \"url\": url,\n",
    "#                         \"source\": \"agentic\"\n",
    "#                     }\n",
    "#                 ))\n",
    "\n",
    "#             ac = AgenticChunker()  # Reset after each document\n",
    "\n",
    "#         except Exception as e:\n",
    "#             print(f\"[Warning] Skipped document: {title}, error: {e}\")\n",
    "#             continue\n",
    "\n",
    "#     return chunked_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafe89c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"islamic_etiquette_knowledge_base.json\", \"r\") as f1, open(\"Quran_app_Documentation.json\", \"r\") as f2:\n",
    "#     etiquette_data = json.load(f1)\n",
    "#     quran_app_data = json.load(f2)\n",
    "\n",
    "# # combined_documents = etiquette_data + quran_app_data\n",
    "# combined_documents = quran_app_data\n",
    "\n",
    "# # Perform agentic chunking\n",
    "# docs = perform_agentic_chunking_with_metadata(combined_documents, prompt)\n",
    "# print(docs[:2])\n",
    "\n",
    "# # if not docs:\n",
    "# #     raise ValueError(\"No chunked documents found. Please check your chunking process and input data.\")\n",
    "\n",
    "# # # Build indices\n",
    "# # bm25, faiss_index, embeddings, corpus, metadata, chroma = build_index(docs)\n",
    "\n",
    "# # # Example query\n",
    "# # query = \"The Quran app is good but not helpful in understanding the Quranic verses.\"\n",
    "# # prompt = generate_response(query, bm25, faiss_index, corpus, metadata, chroma)\n",
    "# # print(\"\\nGenerated Prompt:\\n\")\n",
    "# # print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242fd96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Index construction\n",
    "# def build_index(documents: list):\n",
    "#     all_chunks = [doc.page_content for doc in documents]\n",
    "#     metadata = [doc.metadata for doc in documents]\n",
    "\n",
    "#     # Sparse (BM25)\n",
    "#     tokenized_corpus = [chunk.split(\" \") for chunk in all_chunks]\n",
    "#     bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "#     # Dense Embeddings\n",
    "#     embedding_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2', device=device)\n",
    "#     dense_embeddings = embedding_model.encode(all_chunks, convert_to_numpy=True, normalize_embeddings=True)\n",
    "#     dim = dense_embeddings.shape[1]\n",
    "\n",
    "#     # FAISS (HNSW)\n",
    "#     index = faiss.IndexHNSWFlat(dim, 32)\n",
    "#     index.hnsw.efConstruction = 40\n",
    "#     faiss.normalize_L2(dense_embeddings)\n",
    "#     index.add(dense_embeddings)\n",
    "\n",
    "#     # Chroma\n",
    "#     chroma_db = Chroma.from_texts(\n",
    "#         texts=all_chunks,\n",
    "#         embedding=HuggingFaceEmbeddings(model_name='sentence-transformers/all-mpnet-base-v2'),\n",
    "#         metadatas=metadata,\n",
    "#         persist_directory=\"./chroma_agentic\"\n",
    "#     )\n",
    "\n",
    "#     return bm25, index, dense_embeddings, all_chunks, metadata, chroma_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead36618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Hybrid retrieval\n",
    "# # def retrieve_context(query: str, bm25, faiss_index, corpus: list, metadata: list, top_k: int = 50, rerank_k: int = 10) -> tuple:\n",
    "# #     cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2', device=device)\n",
    "# #     embedding_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2', device=device)\n",
    "\n",
    "# #     tokenized_query = query.split(\" \")\n",
    "# #     bm25_scores = bm25.get_scores(tokenized_query)\n",
    "# #     bm25_top_idx = np.argsort(bm25_scores)[::-1][:top_k]\n",
    "\n",
    "# #     query_emb = embedding_model.encode(query, convert_to_numpy=True, normalize_embeddings=True)\n",
    "# #     faiss.normalize_L2(query_emb.reshape(1, -1))\n",
    "# #     _, dense_top_idx = faiss_index.search(query_emb.reshape(1, -1), top_k)\n",
    "\n",
    "# #     candidate_indices = set(bm25_top_idx) | set(dense_top_idx[0])\n",
    "# #     candidates = [(i, corpus[i], metadata[i]) for i in candidate_indices]\n",
    "\n",
    "# #     pairs = [[query, chunk] for _, chunk, _ in candidates]\n",
    "# #     scores = cross_encoder.predict(pairs)\n",
    "# #     reranked = sorted(zip(scores, candidates), key=lambda x: x[0], reverse=True)[:rerank_k]\n",
    "\n",
    "# #     contexts = [chunk for _, (_, chunk, _) in reranked]\n",
    "# #     docs = [meta for _, (_, _, meta) in reranked]\n",
    "# #     return contexts, docs\n",
    "\n",
    "# # Hybrid retrieval with Chroma\n",
    "# def retrieve_context(query: str, bm25, faiss_index, corpus: List[str], metadata: List[dict], chroma_db, top_k: int = 50, rerank_k: int = 15) -> tuple:\n",
    "#     cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2', device=device)\n",
    "#     embedding_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2', device=device)\n",
    "\n",
    "#     # BM25 retrieval\n",
    "#     tokenized_query = query.split(\" \")\n",
    "#     bm25_scores = bm25.get_scores(tokenized_query)\n",
    "#     bm25_top_idx = np.argsort(bm25_scores)[::-1][:top_k]\n",
    "\n",
    "#     # FAISS retrieval\n",
    "#     query_emb = embedding_model.encode(query, convert_to_numpy=True, normalize_embeddings=True)\n",
    "#     faiss.normalize_L2(query_emb.reshape(1, -1))\n",
    "#     _, dense_top_idx = faiss_index.search(query_emb.reshape(1, -1), top_k)\n",
    "\n",
    "#     # Chroma retrieval\n",
    "#     chroma_results = chroma_db.similarity_search_with_score(query, k=top_k)\n",
    "#     chroma_top_idx = [corpus.index(doc.page_content) for doc, _ in chroma_results if doc.page_content in corpus]\n",
    "\n",
    "#     # Combine and deduplicate\n",
    "#     candidate_indices = set(bm25_top_idx) | set(dense_top_idx[0]) | set(chroma_top_idx)\n",
    "#     candidates = [(i, corpus[i], metadata[i]) for i in candidate_indices if i < len(corpus)]\n",
    "\n",
    "#     # Rerank\n",
    "#     pairs = [[query, chunk] for _, chunk, _ in candidates]\n",
    "#     scores = cross_encoder.predict(pairs)\n",
    "#     reranked = sorted(zip(scores, candidates), key=lambda x: x[0], reverse=True)[:rerank_k]\n",
    "\n",
    "#     contexts = [chunk for _, (_, chunk, _) in reranked]\n",
    "#     docs = [meta for _, (_, _, meta) in reranked]\n",
    "#     return contexts, docs\n",
    "\n",
    "# # Generate response (prompt only)\n",
    "# def generate_response(query: str, bm25, faiss_index, corpus: list, metadata: list) -> str:\n",
    "#     contexts, docs = retrieve_context(query, bm25, faiss_index, corpus, metadata)\n",
    "#     combined_context = \"\\n\\n\".join([f\"{doc['source']}:\\n{ctx}\" for ctx, doc in zip(contexts, docs)])\n",
    "#     prompt = f\"Retrieved Chunks:\\n{combined_context}\\n\\nQuery: {query}\"\n",
    "#     return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06850f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, doc in enumerate(docs):\n",
    "#     print(f\"--- Document {i} ---\")\n",
    "#     print(f\"Content: {doc.page_content}\")\n",
    "#     print(f\"Metadata: {doc.metadata}\")\n",
    "#     print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
