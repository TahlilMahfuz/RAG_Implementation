{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1122a5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import uuid\n",
    "import numpy as np\n",
    "import torch\n",
    "import faiss\n",
    "from dotenv import load_dotenv\n",
    "from typing import Optional\n",
    "from rich import print\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "from rank_bm25 import BM25Okapi\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "from cerebras.cloud.sdk import Cerebras\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# AgenticChunker class (from agentic_chunker.py with minor optimizations)\n",
    "class AgenticChunker:\n",
    "    def __init__(self, cerebras_api_key: Optional[str] = None):\n",
    "        self.chunks = {}\n",
    "        self.id_truncate_limit = 5\n",
    "        self.generate_new_metadata_ind = True\n",
    "        self.print_logging = True\n",
    "\n",
    "        if cerebras_api_key is None:\n",
    "            cerebras_api_key = os.getenv(\"CEREBRAS_API_KEY\")\n",
    "        if cerebras_api_key is None:\n",
    "            raise ValueError(\"CEREBRAS_API_KEY not provided or found in environment variables\")\n",
    "\n",
    "        self.client = Cerebras(api_key=cerebras_api_key)\n",
    "        self.model = \"llama-4-scout-17b-16e-instruct\"\n",
    "\n",
    "    def _llm_invoke(self, prompt: str) -> str:\n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                model=self.model,\n",
    "            )\n",
    "            return response.choices[0].message.content.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"[Error] LLM invocation failed: {e}\")\n",
    "            return \"\"\n",
    "\n",
    "    def add_propositions(self, propositions: list):\n",
    "        for proposition in propositions:\n",
    "            self.add_proposition(proposition)\n",
    "\n",
    "    def add_proposition(self, proposition: str):\n",
    "        if self.print_logging:\n",
    "            print(f\"\\nAdding: '{proposition}'\")\n",
    "        if not self.chunks:\n",
    "            if self.print_logging:\n",
    "                print(\"No chunks, creating a new one\")\n",
    "            self._create_new_chunk(proposition)\n",
    "            return\n",
    "\n",
    "        chunk_id = self._find_relevant_chunk(proposition)\n",
    "        if chunk_id:\n",
    "            if self.print_logging:\n",
    "                print(f\"Chunk Found ({self.chunks[chunk_id]['chunk_id']}), adding to: {self.chunks[chunk_id]['title']}\")\n",
    "            self.add_proposition_to_chunk(chunk_id, proposition)\n",
    "        else:\n",
    "            if self.print_logging:\n",
    "                print(\"No chunks found\")\n",
    "            self._create_new_chunk(proposition)\n",
    "\n",
    "    def add_proposition_to_chunk(self, chunk_id: str, proposition: str):\n",
    "        self.chunks[chunk_id]['propositions'].append(proposition)\n",
    "        if self.generate_new_metadata_ind:\n",
    "            self.chunks[chunk_id]['summary'] = self._update_chunk_summary(self.chunks[chunk_id])\n",
    "            self.chunks[chunk_id]['title'] = self._update_chunk_title(self.chunks[chunk_id])\n",
    "\n",
    "    def _update_chunk_summary(self, chunk: dict) -> str:\n",
    "        prompt = (\n",
    "            \"You are the steward of a group of chunks representing groups of sentences on a similar topic.\\n\"\n",
    "            \"A new proposition was added to a chunk. Generate a brief 1-sentence summary for the chunk.\\n\"\n",
    "            f\"Chunk's propositions:\\n\" + \"\\n\".join(chunk['propositions']) +\n",
    "            f\"\\nCurrent chunk summary:\\n{chunk['summary']}\"\n",
    "        )\n",
    "        return self._llm_invoke(prompt)\n",
    "\n",
    "    def _update_chunk_title(self, chunk: dict) -> str:\n",
    "        prompt = (\n",
    "            \"You are the steward of a group of chunks representing groups of sentences on a similar topic.\\n\"\n",
    "            \"A new proposition was added to a chunk. Generate a brief updated chunk title.\\n\"\n",
    "            f\"Chunk's propositions:\\n\" + \"\\n\".join(chunk['propositions']) +\n",
    "            f\"\\nChunk summary:\\n{chunk['summary']}\\n\"\n",
    "            f\"Current chunk title:\\n{chunk['title']}\"\n",
    "        )\n",
    "        return self._llm_invoke(prompt)\n",
    "\n",
    "    def _get_new_chunk_summary(self, proposition: str) -> str:\n",
    "        prompt = (\n",
    "            \"You are the steward of a group of chunks representing groups of sentences on a similar topic.\\n\"\n",
    "            \"Generate a brief 1-sentence summary for a new chunk based on this proposition:\\n\" + proposition\n",
    "        )\n",
    "        return self._llm_invoke(prompt)\n",
    "\n",
    "    def _get_new_chunk_title(self, summary: str) -> str:\n",
    "        prompt = (\n",
    "            \"You are the steward of a group of chunks representing groups of sentences on a similar topic.\\n\"\n",
    "            \"Generate a brief few-word chunk title for this summary:\\n\" + summary\n",
    "        )\n",
    "        return self._llm_invoke(prompt)\n",
    "\n",
    "    def _create_new_chunk(self, proposition: str):\n",
    "        new_chunk_id = str(uuid.uuid4())[:self.id_truncate_limit]\n",
    "        new_chunk_summary = self._get_new_chunk_summary(proposition)\n",
    "        new_chunk_title = self._get_new_chunk_title(new_chunk_summary)\n",
    "        self.chunks[new_chunk_id] = {\n",
    "            'chunk_id': new_chunk_id,\n",
    "            'propositions': [proposition],\n",
    "            'title': new_chunk_title,\n",
    "            'summary': new_chunk_summary,\n",
    "            'chunk_index': len(self.chunks)\n",
    "        }\n",
    "        if self.print_logging:\n",
    "            print(f\"Created new chunk ({new_chunk_id}): {new_chunk_title}\")\n",
    "\n",
    "    def get_chunk_outline(self) -> str:\n",
    "        chunk_outline = \"\"\n",
    "        for chunk_id, chunk in self.chunks.items():\n",
    "            single_chunk_string = f\"\"\"Chunk ({chunk['chunk_id']}): {chunk['title']}\\nSummary: {chunk['summary']}\\n\\n\"\"\"\n",
    "            chunk_outline += single_chunk_string\n",
    "        return chunk_outline\n",
    "\n",
    "    def _find_relevant_chunk(self, proposition: str) -> Optional[str]:\n",
    "        current_chunk_outline = self.get_chunk_outline()\n",
    "        prompt = (\n",
    "            \"Determine if the 'Proposition' should belong to any existing chunks.\\n\"\n",
    "            \"If it should join a chunk, return the chunk id.\\n\"\n",
    "            \"If not, return 'No chunks'.\\n\"\n",
    "            f\"Current Chunks:\\n--Start of current chunks--\\n{current_chunk_outline}\\n--End of current chunks--\\n\"\n",
    "            f\"Proposition:\\n{proposition}\"\n",
    "        )\n",
    "        chunk_found = self._llm_invoke(prompt).strip()\n",
    "        if len(chunk_found) == self.id_truncate_limit and chunk_found in self.chunks:\n",
    "            return chunk_found\n",
    "        return None\n",
    "\n",
    "    def get_chunks(self, get_type: str = 'dict') -> list:\n",
    "        if get_type == 'dict':\n",
    "            return self.chunks\n",
    "        if get_type == 'list_of_strings':\n",
    "            return [\" \".join(chunk['propositions']) for chunk in self.chunks.values()]\n",
    "\n",
    "    def pretty_print_chunks(self):\n",
    "        print(f\"\\nYou have {len(self.chunks)} chunks\\n\")\n",
    "        for chunk_id, chunk in self.chunks.items():\n",
    "            print(f\"Chunk #{chunk['chunk_index']}\")\n",
    "            print(f\"Chunk ID: {chunk_id}\")\n",
    "            print(f\"Summary: {chunk['summary']}\")\n",
    "            print(f\"Propositions:\")\n",
    "            for prop in chunk['propositions']:\n",
    "                print(f\"    - {prop}\")\n",
    "            print(\"\\n\")\n",
    "\n",
    "    def pretty_print_chunk_outline(self):\n",
    "        print(\"Chunk Outline\\n\")\n",
    "        print(self.get_chunk_outline())\n",
    "\n",
    "# Proposition extraction (simplified from Retriver.ipynb)\n",
    "def extract_propositions(text: str, chunker: AgenticChunker) -> list:\n",
    "    prompt = (\n",
    "        \"You are an expert at extracting key propositions from text.\\n\"\n",
    "        \"Break down the following text into a list of concise, standalone propositions.\\n\"\n",
    "        \"Each proposition should be a complete sentence capturing a single idea.\\n\"\n",
    "        \"Text:\\n\" + text\n",
    "    )\n",
    "    response = chunker._llm_invoke(prompt)\n",
    "    propositions = [line.strip() for line in response.split(\"\\n\") if line.strip()]\n",
    "    return propositions\n",
    "\n",
    "# Agentic chunking with metadata\n",
    "def perform_agentic_chunking_with_metadata(documents_json: list) -> list:\n",
    "    ac = AgenticChunker()\n",
    "    chunked_docs = []\n",
    "\n",
    "    for doc in documents_json:\n",
    "        text = doc.get(\"text\", \"\")\n",
    "        title = doc.get(\"title\", \"Unknown Title\")\n",
    "        url = doc.get(\"url\", \"Unknown URL\")\n",
    "\n",
    "        try:\n",
    "            propositions = extract_propositions(text, ac)\n",
    "            ac.add_propositions(propositions)\n",
    "\n",
    "            agentic_chunks = ac.get_chunks(get_type=\"list_of_strings\")\n",
    "            for chunk_text in agentic_chunks:\n",
    "                chunked_docs.append(Document(\n",
    "                    page_content=chunk_text,\n",
    "                    metadata={\n",
    "                        \"title\": title,\n",
    "                        \"url\": url,\n",
    "                        \"source\": \"agentic\"\n",
    "                    }\n",
    "                ))\n",
    "\n",
    "            ac = AgenticChunker()  # Reset after each document\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[Warning] Skipped document: {title}, error: {e}\")\n",
    "            continue\n",
    "\n",
    "    return chunked_docs\n",
    "\n",
    "# Index construction\n",
    "def build_index(documents: list):\n",
    "    all_chunks = [doc.page_content for doc in documents]\n",
    "    metadata = [doc.metadata for doc in documents]\n",
    "\n",
    "    # Sparse (BM25)\n",
    "    tokenized_corpus = [chunk.split(\" \") for chunk in all_chunks]\n",
    "    bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "    # Dense Embeddings\n",
    "    embedding_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2', device=device)\n",
    "    dense_embeddings = embedding_model.encode(all_chunks, convert_to_numpy=True, normalize_embeddings=True)\n",
    "    dim = dense_embeddings.shape[1]\n",
    "\n",
    "    # FAISS (HNSW)\n",
    "    index = faiss.IndexHNSWFlat(dim, 32)\n",
    "    index.hnsw.efConstruction = 40\n",
    "    faiss.normalize_L2(dense_embeddings)\n",
    "    index.add(dense_embeddings)\n",
    "\n",
    "    # Chroma\n",
    "    chroma_db = Chroma.from_texts(\n",
    "        texts=all_chunks,\n",
    "        embedding=HuggingFaceEmbeddings(model_name='sentence-transformers/all-mpnet-base-v2'),\n",
    "        metadatas=metadata,\n",
    "        persist_directory=\"./chroma_agentic\"\n",
    "    )\n",
    "\n",
    "    return bm25, index, dense_embeddings, all_chunks, metadata, chroma_db\n",
    "\n",
    "# Hybrid retrieval\n",
    "def retrieve_context(query: str, bm25, faiss_index, corpus: list, metadata: list, top_k: int = 50, rerank_k: int = 10) -> tuple:\n",
    "    cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2', device=device)\n",
    "    embedding_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2', device=device)\n",
    "\n",
    "    tokenized_query = query.split(\" \")\n",
    "    bm25_scores = bm25.get_scores(tokenized_query)\n",
    "    bm25_top_idx = np.argsort(bm25_scores)[::-1][:top_k]\n",
    "\n",
    "    query_emb = embedding_model.encode(query, convert_to_numpy=True, normalize_embeddings=True)\n",
    "    faiss.normalize_L2(query_emb.reshape(1, -1))\n",
    "    _, dense_top_idx = faiss_index.search(query_emb.reshape(1, -1), top_k)\n",
    "\n",
    "    candidate_indices = set(bm25_top_idx) | set(dense_top_idx[0])\n",
    "    candidates = [(i, corpus[i], metadata[i]) for i in candidate_indices]\n",
    "\n",
    "    pairs = [[query, chunk] for _, chunk, _ in candidates]\n",
    "    scores = cross_encoder.predict(pairs)\n",
    "    reranked = sorted(zip(scores, candidates), key=lambda x: x[0], reverse=True)[:rerank_k]\n",
    "\n",
    "    contexts = [chunk for _, (_, chunk, _) in reranked]\n",
    "    docs = [meta for _, (_, _, meta) in reranked]\n",
    "    return contexts, docs\n",
    "\n",
    "# Generate response (prompt only)\n",
    "def generate_response(query: str, bm25, faiss_index, corpus: list, metadata: list) -> str:\n",
    "    contexts, docs = retrieve_context(query, bm25, faiss_index, corpus, metadata)\n",
    "    combined_context = \"\\n\\n\".join([f\"{doc['source']}:\\n{ctx}\" for ctx, doc in zip(contexts, docs)])\n",
    "    prompt = f\"Retrieved Chunks:\\n{combined_context}\\n\\nQuery: {query}\"\n",
    "    return prompt\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Load JSON data\n",
    "        with open(\"islamic_etiquette_knowledge_base.json\", \"r\") as f1, open(\"Quran_app_Documentation.json\", \"r\") as f2:\n",
    "            etiquette_data = json.load(f1)\n",
    "            quran_app_data = json.load(f2)\n",
    "\n",
    "        combined_documents = etiquette_data + quran_app_data\n",
    "\n",
    "        # Perform agentic chunking\n",
    "        docs = perform_agentic_chunking_with_metadata(combined_documents)\n",
    "\n",
    "        if not docs:\n",
    "            raise ValueError(\"No chunked documents found. Please check your chunking process and input data.\")\n",
    "\n",
    "        # Build indices\n",
    "        bm25, faiss_index, embeddings, corpus, metadata, chroma = build_index(docs)\n",
    "\n",
    "        # Example query\n",
    "        query = \"What does the Quran say about Riba?\"\n",
    "        prompt = generate_response(query, bm25, faiss_index, corpus, metadata)\n",
    "        print(\"\\nGenerated Prompt:\\n\")\n",
    "        print(prompt)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] Main execution failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d1c254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "Generated Prompt:\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "Generated Prompt:\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Retrieved Chunks:\n",
       "agentic:\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">75</span>. The Quran encourages us to consult with others and be just.\n",
       "\n",
       "agentic:\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">74</span>. The Quran guides us to seek forgiveness and pardon others.\n",
       "\n",
       "agentic:\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span>. The Quran commands us to <span style=\"color: #008000; text-decoration-color: #008000\">\"speak kindly to mankind\"</span> <span style=\"font-weight: bold\">(</span>Quran <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">2:83</span><span style=\"font-weight: bold\">)</span>.\n",
       "\n",
       "agentic:\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">73</span>. The Quran describes the Prophet as gentle and merciful.\n",
       "\n",
       "agentic:\n",
       "**Quranic and Prophetic Foundations**\n",
       "\n",
       "agentic:\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span>. Allah loves those who are constantly repentant and purify themselves <span style=\"font-weight: bold\">(</span>Quran <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">2:222</span><span style=\"font-weight: bold\">)</span>.\n",
       "\n",
       "agentic:\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>. The article is helpful to the author despite their not being of the faith.\n",
       "\n",
       "agentic:\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>. Think good of others.\n",
       "\n",
       "agentic:\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. The guide is specifically designed for non-Arabic speakers.\n",
       "\n",
       "agentic:\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>. Learning good manners is about following the Sunnah and earning the blessings of Allah.\n",
       "\n",
       "Query: The quran app is good but not helpful in understanding the Quranic verses.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Retrieved Chunks:\n",
       "agentic:\n",
       "\u001b[1;36m75\u001b[0m. The Quran encourages us to consult with others and be just.\n",
       "\n",
       "agentic:\n",
       "\u001b[1;36m74\u001b[0m. The Quran guides us to seek forgiveness and pardon others.\n",
       "\n",
       "agentic:\n",
       "\u001b[1;36m21\u001b[0m. The Quran commands us to \u001b[32m\"speak kindly to mankind\"\u001b[0m \u001b[1m(\u001b[0mQuran \u001b[1;92m2:83\u001b[0m\u001b[1m)\u001b[0m.\n",
       "\n",
       "agentic:\n",
       "\u001b[1;36m73\u001b[0m. The Quran describes the Prophet as gentle and merciful.\n",
       "\n",
       "agentic:\n",
       "**Quranic and Prophetic Foundations**\n",
       "\n",
       "agentic:\n",
       "\u001b[1;36m22\u001b[0m. Allah loves those who are constantly repentant and purify themselves \u001b[1m(\u001b[0mQuran \u001b[1;92m2:222\u001b[0m\u001b[1m)\u001b[0m.\n",
       "\n",
       "agentic:\n",
       "\u001b[1;36m5\u001b[0m. The article is helpful to the author despite their not being of the faith.\n",
       "\n",
       "agentic:\n",
       "\u001b[1;36m15\u001b[0m. Think good of others.\n",
       "\n",
       "agentic:\n",
       "\u001b[1;36m2\u001b[0m. The guide is specifically designed for non-Arabic speakers.\n",
       "\n",
       "agentic:\n",
       "\u001b[1;36m3\u001b[0m. Learning good manners is about following the Sunnah and earning the blessings of Allah.\n",
       "\n",
       "Query: The quran app is good but not helpful in understanding the Quranic verses.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example query\n",
    "query = \"The quran app is good but not helpful in understanding the Quranic verses.\"\n",
    "prompt = generate_response(query, bm25, faiss_index, corpus, metadata)\n",
    "print(\"\\nGenerated Prompt:\\n\")\n",
    "print(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa90a04f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "Generated Prompt:\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "Generated Prompt:\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Retrieved Chunks:\n",
       "agentic:\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">75</span>. The Quran encourages us to consult with others and be just.\n",
       "\n",
       "agentic:\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>. The Quran instructs Muslims to respond to greetings with a better one or return it <span style=\"font-weight: bold\">(</span>Surah An-Nisa <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">4:86</span><span style=\"font-weight: bold\">)</span>.\n",
       "\n",
       "agentic:\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">74</span>. The Quran guides us to seek forgiveness and pardon others.\n",
       "\n",
       "agentic:\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span>. The Quran commands us to <span style=\"color: #008000; text-decoration-color: #008000\">\"speak kindly to mankind\"</span> <span style=\"font-weight: bold\">(</span>Quran <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">2:83</span><span style=\"font-weight: bold\">)</span>.\n",
       "\n",
       "agentic:\n",
       "**Quranic and Prophetic Foundations**\n",
       "\n",
       "agentic:\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>. Think good of others.\n",
       "\n",
       "agentic:\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>. Be good to guests.\n",
       "\n",
       "agentic:\n",
       "**Islamic Greetings and Responses**\n",
       "\n",
       "agentic:\n",
       "**Islamic Supplications and Trust in Allah**\n",
       "\n",
       "agentic:\n",
       "**Islamic Teachings**\n",
       "\n",
       "Query: The quran app is good but i can't understand how to use the scheduling feature.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Retrieved Chunks:\n",
       "agentic:\n",
       "\u001b[1;36m75\u001b[0m. The Quran encourages us to consult with others and be just.\n",
       "\n",
       "agentic:\n",
       "\u001b[1;36m5\u001b[0m. The Quran instructs Muslims to respond to greetings with a better one or return it \u001b[1m(\u001b[0mSurah An-Nisa \u001b[1;92m4:86\u001b[0m\u001b[1m)\u001b[0m.\n",
       "\n",
       "agentic:\n",
       "\u001b[1;36m74\u001b[0m. The Quran guides us to seek forgiveness and pardon others.\n",
       "\n",
       "agentic:\n",
       "\u001b[1;36m21\u001b[0m. The Quran commands us to \u001b[32m\"speak kindly to mankind\"\u001b[0m \u001b[1m(\u001b[0mQuran \u001b[1;92m2:83\u001b[0m\u001b[1m)\u001b[0m.\n",
       "\n",
       "agentic:\n",
       "**Quranic and Prophetic Foundations**\n",
       "\n",
       "agentic:\n",
       "\u001b[1;36m15\u001b[0m. Think good of others.\n",
       "\n",
       "agentic:\n",
       "\u001b[1;36m16\u001b[0m. Be good to guests.\n",
       "\n",
       "agentic:\n",
       "**Islamic Greetings and Responses**\n",
       "\n",
       "agentic:\n",
       "**Islamic Supplications and Trust in Allah**\n",
       "\n",
       "agentic:\n",
       "**Islamic Teachings**\n",
       "\n",
       "Query: The quran app is good but i can't understand how to use the scheduling feature.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example query\n",
    "query = \"The quran app is good but i can't understand how to use the scheduling feature.\"\n",
    "\n",
    "prompt = generate_response(query, bm25, faiss_index, corpus, metadata)\n",
    "print(\"\\nGenerated Prompt:\\n\")\n",
    "print(prompt)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
