{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "from rank_bm25 import BM25Okapi\n",
    "import faiss\n",
    "import re\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "embedding_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2', device=device)\n",
    "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2', device=device)\n",
    "gen_tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "# gen_model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer as HFTokenizer\n",
    "\n",
    "# Tokenizer for chunking\n",
    "chunk_tokenizer = HFTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def chunk_text_token_based(text, chunk_size=300, overlap=100):\n",
    "    tokens = chunk_tokenizer.tokenize(text)\n",
    "    chunks = []\n",
    "    for i in range(0, len(tokens), chunk_size - overlap):\n",
    "        chunk = tokens[i:i + chunk_size]\n",
    "        chunk_text = chunk_tokenizer.convert_tokens_to_string(chunk)\n",
    "        chunks.append(chunk_text)\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_index(documents):\n",
    "    all_chunks = []\n",
    "    metadata = []\n",
    "\n",
    "    for doc in documents:\n",
    "        chunks = chunk_text_token_based(doc['text'])\n",
    "        for chunk in chunks:\n",
    "            all_chunks.append(chunk)\n",
    "            metadata.append({'title': doc['title'], 'url': doc['url'], 'text': chunk})\n",
    "\n",
    "    # BM25\n",
    "    tokenized_corpus = [chunk.split(\" \") for chunk in all_chunks]\n",
    "    bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "    # Dense Embeddings\n",
    "    embeddings = embedding_model.encode(all_chunks, convert_to_numpy=True, normalize_embeddings=True)\n",
    "\n",
    "    # Faiss HNSW Index\n",
    "    dim = embeddings.shape[1]\n",
    "    index = faiss.IndexHNSWFlat(dim, 32)\n",
    "    index.hnsw.efConstruction = 40\n",
    "    faiss.normalize_L2(embeddings)\n",
    "    index.add(embeddings)\n",
    "\n",
    "    return bm25, index, embeddings, all_chunks, metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_relevant_context(query, bm25, index, corpus, metadata, top_k=50, rerank_k=5):\n",
    "    # Sparse retrieval\n",
    "    tokenized_query = query.split(\" \")\n",
    "    bm25_scores = bm25.get_scores(tokenized_query)\n",
    "    bm25_top_idx = np.argsort(bm25_scores)[::-1][:top_k]\n",
    "\n",
    "    # Dense retrieval\n",
    "    query_emb = embedding_model.encode(query, convert_to_numpy=True, normalize_embeddings=True)\n",
    "    faiss.normalize_L2(query_emb.reshape(1, -1))\n",
    "    _, dense_top_idx = index.search(query_emb.reshape(1, -1), top_k)\n",
    "\n",
    "    # Merge candidates\n",
    "    candidate_indices = set(bm25_top_idx) | set(dense_top_idx[0])\n",
    "    candidates = [(i, corpus[i], metadata[i]) for i in candidate_indices]\n",
    "\n",
    "    # Rerank with Cross-Encoder\n",
    "    pairs = [[query, text] for _, text, _ in candidates]\n",
    "    scores = cross_encoder.predict(pairs)\n",
    "    reranked = sorted(zip(scores, candidates), key=lambda x: x[0], reverse=True)[:rerank_k]\n",
    "\n",
    "    # Return top reranked contexts and metadata\n",
    "    contexts = [text for _, (_, text, _) in reranked]\n",
    "    docs = [meta for _, (_, _, meta) in reranked]\n",
    "    return contexts, docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(review: str, bm25, index, corpus, metadata) -> str:\n",
    "    contexts, docs = retrieve_relevant_context(review, bm25, index, corpus, metadata)\n",
    "    combined_context = \"\\n\\n\".join([f\"{doc['title']}:\\n{ctx}\" for ctx, doc in zip(contexts, docs)])\n",
    "    prompt = f\"Context:\\n{combined_context}\\n\\nReview: {review}\\n\\nResponse:\"\n",
    "    print(prompt)\n",
    "    # inputs = gen_tokenizer(prompt, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n",
    "    # outputs = gen_model.generate(**inputs, max_new_tokens=150)\n",
    "    # return gen_tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load your Islamic etiquette knowledge base\n",
    "with open('islamic_etiquette_knowledge_base.json') as f:\n",
    "    etiquette_data = json.load(f)\n",
    "\n",
    "# Prepare chunked documents\n",
    "documents = []\n",
    "for entry in etiquette_data:\n",
    "    chunks = chunk_text_token_based(entry['text'])  # use the token-based chunker\n",
    "    for chunk in chunks:\n",
    "        documents.append({\n",
    "            'title': entry['title'],\n",
    "            'url': entry['url'],\n",
    "            'text': chunk\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:\n",
      "SAHIH MUSLIM, Book 26 : The Book of Salutions and Greetings (KITAB AS-SALAM):\n",
      "the great curer, there is no cure but through thine healing power, which leaves nothing of the disease. ' a ' isha reported that when allah ' s messenger ( may peace be upon him ) came to visit any sick he supplicated for him and said : lord of the people, remove the malady, cure him for thou art a great curer. there is no cure but through thine healing power which leaves no trouble, and in the narration transmitted on the authority of abu bakr there is a slight variation of wording. this hadith has been reported on the authority of ' a ' isha through another chain of transmitters with a slight variation of wording. ' a ' isha reported : allah ' s messenger ( may peace be upon him ) used to recite ( this supplication ) as the words of incantation : \" lord of the people, remove the trouble for in thine hand is the cure ; none is there to relieve him ( the burden of disease ) but only thou. this hadith has been reported on the authority of hisham with the same chain of transmitted. ' a ' isha reported that when any of the members of the household fell ill allah ' s messenger ( may peace be upon him ) used to blow over him by reciting mu ' awwidhatan, and when he suffered from illness of which he died i used to blow over him and rubbed his body with his hand for his hand had\n",
      "\n",
      "Muslim And Arabic Greeting Words And Phrases In Arabic:\n",
      "to say “ hello ” or “ peace. ” it ’ s used mostly between close friends or in quick conversations. when to use it : use it with friends when you don ’ t have time for long greetings. : use it with friends when you don ’ t have time for long greetings. how to respond : you can simply reply with “ salam ” ( سلام ) again. 9. نهارك سعيد ( naharak sa ’ eed ) this is a cheerful and positive greeting, wishing someone happiness throughout the day. it ’ s a great way to lift someone ’ s spirits and make them feel special. when to use it : use it in the morning or afternoon. it ’ s a thoughtful way to greet someone when you want to offer more than just a standard “ good day. ” response : you can simply reply with “ wa naharak as ’ ad ” ( ونهارك اسعد ), meaning “ and may your day be happier. ” 10. كيف الحال ( kayfa al - haal ) this is a common greeting used to ask about someone ’ s well - being. it is similar to asking “ how are you? ” in english. you can use it in all kinds of conversations, from casual to formal. when to use it : you can say kayfa al - haal when you meet someone, whether a friend or a colleague.\n",
      "\n",
      "SAHIH MUSLIM, Book 26 : The Book of Salutions and Greetings (KITAB AS-SALAM):\n",
      "the great curer, there is no cure but through thine healing power, which leaves nothing of the disease. ' a ' isha reported that when allah ' s messenger ( may peace be upon him ) came to visit any sick he supplicated for him and said : lord of the people, remove the malady, cure him for thou art a great curer. there is no cure but through thine healing power which leaves no trouble, and in the narration transmitted on the authority\n",
      "\n",
      "The Islamic Greeting and it’s Etiquette:\n",
      "# # allahu alayhi wasallam ) said, “ don ’ t start with the ( salam ) islamic greeting when encountering jews or christians. ” some scholars see no problem in starting with the islamic greeting. some of the shafies agree with this. this is the opinion of ibn - abbas one of the companions of the prophet. he said that this hadith was special for the jewish of quraizah, not for all of the people of the book. what if the people of the book start with the salams with the muslims. some of the scholars, like ahnaf say that it is allowed to returnsalam and others say it ’ s obligatory. ibn abbass said, “ whoever says assalamu alakum to you, you have to return his greeting even if he was a majos ( fire - worshipper ). he was referring to a verse from surat an - nisaa ( verse 86 ), what can be translated as, “ when a courteous greeting is offered to you, meet it with a greeting still more courteous, or at least of equal courtesy. ” the scholar had agreed upon starting the greeting with the non - muslims is allowed with any word but assalamu alikum, like good morning, how are you? when meeting another muslim shaking hands is highly recommended, along with a great smile, because it increases the love and respect among muslims. it was reported by imam bukhari that\n",
      "\n",
      "SAHIH MUSLIM, Book 26 : The Book of Salutions and Greetings (KITAB AS-SALAM):\n",
      "but now you observe silence about it. you used to say that allah ' s messenger ( may peace be upon him ) said : there is no transitive disease. abu huraira denied having any knowledge of that, but he said that the sick camel should not be taken to the healthy one. harith, however, did not agree with him, which irritated abu huraira and he said to him some words in the abyssinian language. he said to harith : do you know what i said to you? he said : no. abu huraira said : i simply denied having said it. abu salama sad : by my life, abu huraira in fact used to report allah ' s messenger ( may peace be upon him ) having said : there is no transitive disease. i do not know whether abu huraira has forgotten it or he deemed it an abrogated statement in the light of the other one. abu huraira reported allah ' s messenger ( may peace be upon him ) as saying : there is no transitive disease and he also reported along with it : the ill should not be taken to the healthy. this hadith has been reported on the authority of zuhri with the same chain of transmitters. abu huraira reported allah ' s messenger ( may peace be upon him ) as saying : there is no transitive disease, no huma, no star promising rain, no safar. jabir reported allal ' s messenger (\n",
      "\n",
      "Review: The app is great. But it lacks in some manner issue\n",
      "\n",
      "Response:\n",
      "Generated Response:\n",
      " None\n"
     ]
    }
   ],
   "source": [
    "# Build index\n",
    "bm25, index, embeddings, corpus, metadata = build_index(documents)\n",
    "\n",
    "# Run generation\n",
    "review_text = \"The app is great. But it lacks in some manner issue\"\n",
    "response = generate_response(review_text, bm25, index, corpus, metadata)\n",
    "\n",
    "# print with wraptext\n",
    "print(\"Generated Response:\\n\", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
