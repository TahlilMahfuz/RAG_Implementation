{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DPRQuestionEncoder, DPRContextEncoder, DPRQuestionEncoderTokenizer, DPRContextEncoderTokenizer\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "from rank_bm25 import BM25Okapi\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Use GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpr_question_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained('facebook/dpr-question_encoder-single-nq-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/dpr-question_encoder-single-nq-base were not used when initializing DPRQuestionEncoder: ['question_encoder.bert_model.pooler.dense.bias', 'question_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing DPRQuestionEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRQuestionEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "dpr_question_encoder = DPRQuestionEncoder.from_pretrained('facebook/dpr-question_encoder-single-nq-base').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "dpr_context_tokenizer = DPRContextEncoderTokenizer.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/dpr-ctx_encoder-single-nq-base were not used when initializing DPRContextEncoder: ['ctx_encoder.bert_model.pooler.dense.bias', 'ctx_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing DPRContextEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRContextEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Load encoder models\n",
    "dpr_context_encoder = DPRContextEncoder.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-encoder for reranking\n",
    "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator model\n",
    "gen_tokenizer = AutoTokenizer.from_pretrained('google/flan-t5-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_model = AutoModelForSeq2SeqLM.from_pretrained('google/flan-t5-base').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text: str, chunk_size: int = 200, overlap: int = 50):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    for i in range(0, len(words), chunk_size - overlap):\n",
    "        chunks.append(' '.join(words[i:i+chunk_size]))\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('islamic_etiquette_knowledge_base.json') as f:\n",
    "    etiquette_data = json.load(f)\n",
    "\n",
    "raw_entries = etiquette_data\n",
    "# Create passages\n",
    "passages = []\n",
    "metadata = []\n",
    "for entry in raw_entries:\n",
    "    for chunk in chunk_text(entry['text']):\n",
    "        passages.append(chunk)\n",
    "        metadata.append({'url': entry['url'], 'title': entry['title'], 'text': chunk})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build BM25 index\n",
    "tokenized_corpus = [p.split() for p in passages]\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "# Move context encoder to the correct device\n",
    "dpr_context_encoder = dpr_context_encoder.to(device)\n",
    "\n",
    "# Build DPR (FAISS) index\n",
    "ctx_embeddings = []\n",
    "for txt in passages:\n",
    "    inputs = dpr_context_tokenizer(txt, return_tensors='pt', truncation=True, max_length=256).to(device)\n",
    "    with torch.no_grad():\n",
    "        emb = dpr_context_encoder(**inputs).pooler_output\n",
    "    ctx_embeddings.append(emb.cpu().numpy())\n",
    "ctx_embeddings = np.vstack(ctx_embeddings)\n",
    "index = faiss.IndexFlatIP(ctx_embeddings.shape[1])\n",
    "faiss.normalize_L2(ctx_embeddings)\n",
    "index.add(ctx_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieval function\n",
    "def retrieve_relevant_context(query: str, top_k: int = 5):\n",
    "    # BM25 retrieval\n",
    "    tokenized_query = query.split()\n",
    "    bm25_scores = bm25.get_scores(tokenized_query)\n",
    "    bm25_top = sorted(range(len(bm25_scores)), key=lambda i: bm25_scores[i], reverse=True)[:top_k]\n",
    "\n",
    "    # DPR retrieval\n",
    "    q_inputs = dpr_question_tokenizer(query, return_tensors='pt', truncation=True, max_length=64).to(device)\n",
    "    with torch.no_grad():\n",
    "        q_emb = dpr_question_encoder(**q_inputs).pooler_output.cpu().numpy()\n",
    "    faiss.normalize_L2(q_emb)\n",
    "    D, I = index.search(q_emb, top_k)\n",
    "    dpr_top = I[0]\n",
    "\n",
    "    # Combine BM25 and DPR\n",
    "    combined = set(bm25_top) | set(dpr_top)\n",
    "    candidates = list(combined)\n",
    "    # Rerank with cross-encoder\n",
    "    cross_in = [(query, passages[idx]) for idx in candidates]\n",
    "    cross_scores = cross_encoder.predict(cross_in)\n",
    "    reranked = [candidates[i] for i in sorted(range(len(cross_scores)), key=lambda i: cross_scores[i], reverse=True)][:top_k]\n",
    "\n",
    "    return [passages[i] for i in reranked], [metadata[i] for i in reranked]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_response(review: str) -> str:\n",
    "    contexts, docs = retrieve_relevant_context(review, top_k=3)\n",
    "    combined_context = \"\\n\\n\".join([f\"[{doc['title']}]({doc['url']}): {ctx}\" for ctx, doc in zip(contexts, docs)])\n",
    "    prompt = f\"Context:\\n{combined_context}\\n\\nReview: {review}\"\n",
    "    print(f\"Prompt: {prompt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Context:\n",
      "[The 75 Good Manners (Commandments) in The Quran](https://blog.une.edu.au/new-england-muslims/2019/11/14/the-75-good-manners-commandments-in-the-quran/comment-page-1/): pure (53:32) Speak nicely, even to the ignorant (25:63) Don’t ask for repayment for favours (76:9) Make room for others at gatherings (58:11) If enemy wants peace, then accept it (8:61) Return a greeting in a better manner (4:86) Don’t remind others of your favours (2:264) Make peace between fighting groups (49:9) Lower your voice and talk moderately (31:19) Don’t let hatred cause you to be unjust (6:108) Don’t ask too many favours from people (2:273) Greet people when entering their home (24:27) Be just, even against yourself & relatives (4:135) Speak gently, even to leaders of disbelief (20:44) Don’t criticize small contributions of others (9:79) Don’t call the Prophet how you call others’ (24:63) Try to make peace between husband & wife (4:128) Don’t call the Prophet from outside his rooms (49:4) Oppression/corruption is worse than killing (2:217) Preach to others in a good and wise manner (16:125) Don’t accuse others of immorality without proof (24:4) Consider wives of the Prophet like your mothers (33:6) Don’t raise your voice above that of the Prophet’s (49:2) Don’t call someone a disbeliever without knowing (4:94) Seek permission before entering someone’s room (24:59) Know your enemies can become your close friends (41:34)\n",
      "\n",
      "[Muslim And Arabic Greeting Words And Phrases In Arabic](https://kalimah-center.com/arabic-greeting-words/): someone’s efforts. (بارك الله فيك): Meaning “May Allah bless you.” This phrase is used in a variety of situations, from offering thanks to praising someone’s efforts. Allah yahmeek (الله يحميك): This means “May Allah protect you.” It’s a heartfelt way to wish someone safety. (الله يحميك): This means “May Allah protect you.” It’s a heartfelt way to wish someone safety. Mashallah (ما شاء الله): Meaning “What Allah has willed,” it’s often said to express admiration or gratitude without invoking jealousy. Jazakallahu khairan (جزاك الله خيرا): Meaning “May Allah reward you with goodness,” it’s often said when someone does a kind act. (جزاك الله خيرا): Meaning “May Allah reward you with goodness,” it’s often said when someone does a kind act. Rahimakallahu (رحمك الله): Meaning “May Allah have mercy on you,” this phrase is often used when speaking about someone who has passed away. By learning these phrases, you’re not just expanding your vocabulary—you’re also gaining insight into the deep respect and care embedded in Arabic communication. Want to Greet People in Arabic with Confidence? You’ve learned some Arabic greetings – that’s great! But wouldn’t it be amazing to use them in real conversations, understand the nuances of each greeting, and\n",
      "\n",
      "[The 75 Good Manners (Commandments) in The Quran](https://blog.une.edu.au/new-england-muslims/2019/11/14/the-75-good-manners-commandments-in-the-quran/comment-page-1/): under you, and consult them in matters (3:159) Verify information from a dubious source before acting upon it (49:6) Don’t remain in the Prophet’s home unnecessarily after a meal (33:53) Those who can should continue to spend on those less fortunate (24:22) Don’t enter homes without permission & return if refused entry (24:27-28) Don’t sit with those who mock religion until they change the subject (4:140) Say it’s not appropriate to talk of slander when it’s mentioned to you (24:16) If required to ask the Prophet’s wives, then do so from behind a screen (33:53) Divorce in an amicable manner instead of keeping & harming your wife (2:231) Punish in an equivalent manner to how you were harmed or be patient (16:126) Differences in color & language are signs of Allah, not means of superiority (49:13) Don’t take women by force, nor take back bridal gift without a valid reason & live with them in kindness (4:19) Share this: Twitter Facebook\n",
      "\n",
      "Review: The app is great. But it lacks in some manner issue\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "review_text = \"The app is great. But it lacks in some manner issue\"\n",
    "print(rag_response(review_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Response generation\n",
    "# def generate_response(review: str) -> str:\n",
    "#     contexts, docs = retrieve_relevant_context(review, top_k=3)\n",
    "#     combined_context = \"\\n\\n\".join([f\"[{doc['title']}]({doc['url']}): {ctx}\" for ctx, doc in zip(contexts, docs)])\n",
    "#     prompt = f\"Context:\\n{combined_context}\\n\\nReview: {review}\\n\\nResponse:\"\n",
    "#     print(f\"Prompt: {prompt}\") \n",
    "\n",
    "#     inputs = gen_tokenizer(prompt, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n",
    "#     outputs = gen_model.generate(**inputs, max_new_tokens=150)\n",
    "#     return gen_tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review_text = \"The app is great. But it lacks in some manner issue\"\n",
    "# print(generate_response(review_text))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
