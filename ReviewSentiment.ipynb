{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ef78d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Enable progress_apply for pandas\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee0a86e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load user reviews from the SQLite database\n",
    "db_path = \"Auto_Reply_v3.db\"\n",
    "conn = sqlite3.connect(db_path)\n",
    "queries = [\n",
    "    'SELECT \"translation\" AS Review FROM All_Reviews',\n",
    "    'SELECT \"translation\" AS Review FROM \"Auto Reply Hadith\"',\n",
    "    'SELECT \"translation\" AS Review FROM Auto_Reply_Reviews',\n",
    "    'SELECT \"translation\" AS Review FROM Auto_Reply_Reviews_Al_Quran'\n",
    "]\n",
    "dfs = [pd.read_sql_query(q, conn) for q in queries]\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19d82821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load the tokenizer and model for sequence classification\n",
    "model_name = \"iSathyam03/McD_Reviews_Sentiment_Analysis\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "638b0668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 'iSathyam03/McD_Reviews_Sentiment_Analysis' on cuda.\n"
     ]
    }
   ],
   "source": [
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(f\"Loaded '{model_name}' on {device}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c88f7c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting sentiment analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70460/70460 [04:01<00:00, 291.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 70460 reviews. Results saved to 'McD_Reviews_Sentiment_Results.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Sentiment prediction function using logits\n",
    "def predict_sentiment(text):\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return None\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=512\n",
    "    )\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    prediction = torch.argmax(logits, dim=1).item()\n",
    "    sentiment_labels = {0: \"Negative\", 1: \"Neutral\", 2: \"Positive\"}\n",
    "    return sentiment_labels.get(prediction)\n",
    "\n",
    "# 4. Apply sentiment prediction with progress bar\n",
    "print(\"Starting sentiment analysis...\")\n",
    "df['sentiment'] = df['Review'].progress_apply(predict_sentiment)\n",
    "\n",
    "# 5. Save the results to CSV\n",
    "df.to_csv('McD_Reviews_Sentiment_Results.csv', index=False)\n",
    "print(f\"Processed {len(df)} reviews. Results saved to 'McD_Reviews_Sentiment_Results.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83549d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 70460 reviews. Results saved to 'McD_Reviews_Sentiment_Results.csv'.\n"
     ]
    }
   ],
   "source": [
    "# 5. Generate automated replies based on sentiment\n",
    "\n",
    "def generate_reply(sentiment):\n",
    "    if sentiment == \"Positive\":\n",
    "        return (\n",
    "            \"BarakAllahu feekum for your kind words and support. Pray for us so that Allah may accept our efforts. Visit gtaf.org to check our other apps and share with others in sha Allah!\"\n",
    "        )\n",
    "    elif sentiment == \"Negative\":\n",
    "        return (\n",
    "            \"Assalamu 'alaykum dear user. We would love to make your experience better in sha Allah. If you are still facing the same issues or have any feature requests, please provide your feedback on feedback.gtaf.org. JazakAllahu khayran.\"\n",
    "        )\n",
    "    else:\n",
    "        return \"JazakAllahu khayran for your review! If you face any issues or have feature requests, please provide your feedback on feedback.gtaf.org.\"\n",
    "\n",
    "# Apply reply generation\n",
    "df['reply'] = df['sentiment'].apply(generate_reply)\n",
    "\n",
    "# 6. Save the results to CSV including Review, sentiment, and reply\n",
    "df.to_csv('McD_Reviews_Sentiment_Results.csv', index=False)\n",
    "print(f\"Processed {len(df)} reviews. Results saved to 'McD_Reviews_Sentiment_Results.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
